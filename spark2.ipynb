{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('satisfaction_level', 'double'), ('last_evaluation', 'double'), ('number_project', 'int'), ('average_montly_hours', 'int'), ('time_spend_company', 'int'), ('Work_accident', 'int'), ('left', 'int'), ('promotion_last_5years', 'int'), ('sales', 'string'), ('salary', 'string')]\n",
      "root\n",
      " |-- satisfaction_level: double (nullable = true)\n",
      " |-- last_evaluation: double (nullable = true)\n",
      " |-- number_project: integer (nullable = true)\n",
      " |-- average_montly_hours: integer (nullable = true)\n",
      " |-- time_spend_company: integer (nullable = true)\n",
      " |-- Work_accident: integer (nullable = true)\n",
      " |-- left: integer (nullable = true)\n",
      " |-- promotion_last_5years: integer (nullable = true)\n",
      " |-- sales: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/HR_comma_sep.csv\"\n",
    "dataset = spark.read.options(header=\"true\", parserLib=\"univocity\", inferSchema=\"true\").csv(data_path)\n",
    "cols = dataset.columns\n",
    "print dataset.dtypes\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categoricalColumns = [\"sales\", \"salary\"]\n",
    "stages = []\n",
    "\n",
    "for categoricalCol in categoricalColumns: \n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n",
    "    encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OneHotEncoder_402c8c177081d0a9f247,\n",
       " StringIndexer_4e51894d7dfab856a577,\n",
       " OneHotEncoder_4fb59c5eb9d88f055191,\n",
       " StringIndexer_4b459cdee37211cebbc9]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_string_indexer = StringIndexer(inputCol = \"left\", outputCol = \"label\")\n",
    "stages += [label_string_indexer]\n",
    "stages[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_48a1a66e1c344f92ac23,\n",
       " OneHotEncoder_402c8c177081d0a9f247,\n",
       " StringIndexer_4e51894d7dfab856a577,\n",
       " OneHotEncoder_4fb59c5eb9d88f055191,\n",
       " StringIndexer_4b459cdee37211cebbc9]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericColumns = ['number_project',\n",
    "                  'average_montly_hours',\n",
    "                  'time_spend_company',\n",
    "                  'Work_accident', \n",
    "                  'promotion_last_5years']\n",
    "\n",
    "assemblerInputs = map(lambda c: c + \"classVec\", categoricalColumns) + numericColumns\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "stages += [assembler]\n",
    "\n",
    "stages[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'time_spend_company', 'Work_accident', 'left', 'promotion_last_5years', 'sales', 'salary']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10502121397148648"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print dataset.columns\n",
    "dataset.corr(col1=\"satisfaction_level\", col2=\"last_evaluation\")\n",
    "#dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
      "|label|            features|satisfaction_level|last_evaluation|number_project|average_montly_hours|time_spend_company|Work_accident|left|promotion_last_5years|sales|salary|\n",
      "+-----+--------------------+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.38|           0.53|             2|                 157|                 3|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,10,11,12,1...|               0.8|           0.86|             5|                 262|                 6|            0|   1|                    0|sales|medium|\n",
      "|  1.0|(16,[0,10,11,12,1...|              0.11|           0.88|             7|                 272|                 4|            0|   1|                    0|sales|medium|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.72|           0.87|             5|                 223|                 5|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.37|           0.52|             2|                 159|                 3|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.41|            0.5|             2|                 153|                 3|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|               0.1|           0.77|             6|                 247|                 4|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.92|           0.85|             5|                 259|                 5|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.89|            1.0|             5|                 224|                 5|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.42|           0.53|             2|                 142|                 3|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.45|           0.54|             2|                 135|                 3|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.11|           0.81|             6|                 305|                 4|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.84|           0.92|             4|                 234|                 5|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.41|           0.55|             2|                 148|                 3|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.36|           0.56|             2|                 137|                 3|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.38|           0.54|             2|                 143|                 3|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.45|           0.47|             2|                 160|                 3|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.78|           0.99|             4|                 255|                 6|            0|   1|                    0|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.45|           0.51|             2|                 160|                 3|            1|   1|                    1|sales|   low|\n",
      "|  1.0|(16,[0,9,11,12,13...|              0.76|           0.89|             5|                 262|                 5|            0|   1|                    0|sales|   low|\n",
      "+-----+--------------------+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(dataset)\n",
    "dataset = pipelineModel.transform(dataset)\n",
    "selectedcols = [\"label\", \"features\"] + cols\n",
    "dataset = dataset.select(selectedcols)\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10567\n",
      "4432\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print trainingData.count()\n",
    "print testData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the dataset with various machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- satisfaction_level: double (nullable = true)\n",
      " |-- last_evaluation: double (nullable = true)\n",
      " |-- number_project: integer (nullable = true)\n",
      " |-- average_montly_hours: integer (nullable = true)\n",
      " |-- time_spend_company: integer (nullable = true)\n",
      " |-- Work_accident: integer (nullable = true)\n",
      " |-- left: integer (nullable = true)\n",
      " |-- promotion_last_5years: integer (nullable = true)\n",
      " |-- sales: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=750)\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       0.0|[0.77697641302549...|\n",
      "|  0.0|       0.0|[0.59339454079627...|\n",
      "|  0.0|       0.0|[0.65793686279020...|\n",
      "|  0.0|       0.0|[0.77017435807291...|\n",
      "|  0.0|       0.0|[0.76106183794182...|\n",
      "|  0.0|       0.0|[0.69795973045569...|\n",
      "|  0.0|       0.0|[0.75281798642968...|\n",
      "|  0.0|       0.0|[0.75226165823401...|\n",
      "|  0.0|       0.0|[0.69289775060790...|\n",
      "|  0.0|       0.0|[0.69289775060790...|\n",
      "|  0.0|       0.0|[0.68586113805961...|\n",
      "|  0.0|       0.0|[0.74153270537012...|\n",
      "|  0.0|       0.0|[0.62076415096320...|\n",
      "|  0.0|       0.0|[0.73576577328656...|\n",
      "|  0.0|       0.0|[0.67678068206384...|\n",
      "|  0.0|       0.0|[0.67547231581425...|\n",
      "|  0.0|       0.0|[0.73109328439357...|\n",
      "|  0.0|       0.0|[0.72814659424960...|\n",
      "|  0.0|       0.0|[0.52874904179595...|\n",
      "|  0.0|       0.0|[0.59081153751529...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected = predictions.select(\"label\", \"prediction\", \"probability\")\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC\n",
      "0.719831991107\n",
      "areaUnderPR\n",
      "0.379709825066\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print evaluator.getMetricName()\n",
    "print evaluator.evaluate(predictions)\n",
    "evaluator.setMetricName(\"areaUnderPR\")\n",
    "print evaluator.getMetricName()\n",
    "print evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossvalidation on logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .addGrid(lr.maxIter, [1, 5, 10])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\n",
    "#numFolds=10 indicates 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Intercept:  -1.16469160387\n",
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "|  0.0|       0.0|[0.76218415822844...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cvModel = cv.fit(trainingData)\n",
    "predictions = cvModel.transform(testData)\n",
    "evaluator.evaluate(predictions)\n",
    "print 'Model Intercept: ', cvModel.bestModel.intercept\n",
    "weights = cvModel.bestModel.coefficients\n",
    "weights = map(lambda w: (float(w),), weights)  # convert numpy type to float, and to tuple\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\")\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderPR\n",
      "0.619359205776\n",
      "areaUnderPR\n",
      "0.619359205776\n"
     ]
    }
   ],
   "source": [
    "print evaluator.getMetricName()\n",
    "print evaluator.evaluate(predictions)\n",
    "evaluator.setMetricName(\"areaUnderPR\")\n",
    "print evaluator.getMetricName()\n",
    "print evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numNodes =  29\n",
      "depth =  4\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- satisfaction_level: double (nullable = true)\n",
      " |-- last_evaluation: double (nullable = true)\n",
      " |-- number_project: integer (nullable = true)\n",
      " |-- average_montly_hours: integer (nullable = true)\n",
      " |-- time_spend_company: integer (nullable = true)\n",
      " |-- Work_accident: integer (nullable = true)\n",
      " |-- left: integer (nullable = true)\n",
      " |-- promotion_last_5years: integer (nullable = true)\n",
      " |-- sales: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create initial Decision Tree Model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=4)\n",
    "\n",
    "# Train model with Training Data\n",
    "dtModel = dt.fit(trainingData)\n",
    "\n",
    "print \"numNodes = \", dtModel.numNodes\n",
    "print \"depth = \", dtModel.depth\n",
    "\n",
    "# Make predictions on test data using the Transformer.transform() method.\n",
    "predictions = dtModel.transform(testData)\n",
    "predictions.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       1.0|[0.09314140558848...|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       1.0|[0.09314140558848...|\n",
      "|  0.0|       1.0|[0.09314140558848...|\n",
      "|  0.0|       0.0|[0.98165137614678...|\n",
      "|  0.0|       0.0|[0.98165137614678...|\n",
      "|  0.0|       0.0|[0.98165137614678...|\n",
      "|  0.0|       0.0|[0.98165137614678...|\n",
      "|  0.0|       0.0|[0.98165137614678...|\n",
      "|  0.0|       0.0|[0.98165137614678...|\n",
      "|  0.0|       0.0|[0.98165137614678...|\n",
      "|  0.0|       0.0|[0.98165137614678...|\n",
      "|  0.0|       0.0|[0.98165137614678...|\n",
      "|  0.0|       0.0|[0.98165137614678...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\")\n",
    "selected.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9335259176421944"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4ec6b5d0a5714c6df4a1) of depth 4 with 29 nodes\n",
      "  If (feature 11 <= 2.0)\n",
      "   If (feature 12 <= 164.0)\n",
      "    If (feature 12 <= 124.0)\n",
      "     Predict: 0.0\n",
      "    Else (feature 12 > 124.0)\n",
      "     If (feature 13 <= 2.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 13 > 2.0)\n",
      "      Predict: 1.0\n",
      "   Else (feature 12 > 164.0)\n",
      "    If (feature 12 <= 240.0)\n",
      "     If (feature 1 in {0.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 1 not in {0.0})\n",
      "      Predict: 0.0\n",
      "    Else (feature 12 > 240.0)\n",
      "     If (feature 0 in {0.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 not in {0.0})\n",
      "      Predict: 0.0\n",
      "  Else (feature 11 > 2.0)\n",
      "   If (feature 13 <= 3.0)\n",
      "    If (feature 12 <= 283.0)\n",
      "     If (feature 11 <= 6.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 11 > 6.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 12 > 283.0)\n",
      "     If (feature 14 <= 0.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 14 > 0.0)\n",
      "      Predict: 0.0\n",
      "   Else (feature 13 > 3.0)\n",
      "    If (feature 12 <= 219.0)\n",
      "     If (feature 12 <= 213.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 12 > 213.0)\n",
      "      Predict: 0.0\n",
      "    Else (feature 12 > 219.0)\n",
      "     If (feature 11 <= 4.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 11 > 4.0)\n",
      "      Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DTree = dtModel.toDebugString\n",
    "print DTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from bson import json_util\n",
    "from bson.json_util import dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parser\n",
    "def parse(lines):\n",
    "    block = []\n",
    "    while lines :\n",
    "\n",
    "        if lines[0].startswith('If'):\n",
    "            bl = ' '.join(lines.pop(0).split()[1:]).replace('(', '').replace(')', '')\n",
    "            block.append({'name':bl, 'children':parse(lines)})\n",
    "\n",
    "\n",
    "            if lines[0].startswith('Else'):\n",
    "                be = ' '.join(lines.pop(0).split()[1:]).replace('(', '').replace(')', '')\n",
    "                block.append({'name':be, 'children':parse(lines)})\n",
    "        elif not lines[0].startswith(('If','Else')):\n",
    "            block2 = lines.pop(0)\n",
    "            block.append({'name':block2})\n",
    "        else:\n",
    "            break\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_json(tree):\n",
    "    data = []\n",
    "    for line in tree.splitlines() : \n",
    "        if line.strip():\n",
    "            line = line.strip()\n",
    "            data.append(line)\n",
    "        else : break\n",
    "        if not line : break\n",
    "    res = []\n",
    "    res.append({'name':'Root', 'children':parse(data[1:])})\n",
    "    with open('/Users/dylanbao/Desktop/SJSU/297ML/Project/Decision-Tree-Visualization-Spark-master/data/structure.json', 'w') as outfile:\n",
    "        json.dump(res[0], outfile)\n",
    "    print ('Conversion Success !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion Success !\n"
     ]
    }
   ],
   "source": [
    "tree_json(DTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC\n",
      "0.933525917642\n",
      "areaUnderPR\n",
      "0.872263034426\n"
     ]
    }
   ],
   "source": [
    "print evaluator.getMetricName()\n",
    "print evaluator.evaluate(predictions)\n",
    "evaluator.setMetricName(\"areaUnderPR\")\n",
    "print evaluator.getMetricName()\n",
    "print evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossvalidation on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [1,2,6,10])\n",
    "             .addGrid(dt.maxBins, [20,40,80])\n",
    "             .build())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numNodes =  497\n",
      "depth =  10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.896319921308404"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "print \"numNodes = \", cvModel.bestModel.numNodes\n",
    "print \"depth = \", cvModel.bestModel.depth\n",
    "\n",
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(testData)\n",
    "\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       1.0|[0.01932367149758...|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "|  0.0|       0.0|           [1.0,0.0]|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View Best model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\")\n",
    "selected.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderPR\n",
      "0.896319921308\n",
      "areaUnderPR\n",
      "0.896319921308\n"
     ]
    }
   ],
   "source": [
    "print evaluator.getMetricName()\n",
    "print evaluator.evaluate(predictions)\n",
    "evaluator.setMetricName(\"areaUnderPR\")\n",
    "print evaluator.getMetricName()\n",
    "print evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
